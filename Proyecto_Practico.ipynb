{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto práctico\n",
    "\n",
    "## Unidad 3 - Aprendizaje supervisado\n",
    "\n",
    "El proyecto práctico consiste en abordar un problema de clasificación de documentos textuales. Tenemos a nuestra disposición un dataset de noticias de prensa en español publicada por el medio \"CNN Chile\".\n",
    "\n",
    "Las noticias están divididas en 7 categorías temáticas: *'pais','deportes','tendencias','tecnologias','cultura','economia','mundo'*\n",
    "\n",
    "El proyecto se divide en dos partes:\n",
    "\n",
    "- Utilizar al menos 3 estrategías para entrenar modelos de clasificación capaces de clasificar las noticias según su categoría temática.\n",
    "\n",
    "- Explorar cuáles son las características que permiten explicar las decisiones de su modelo.\n",
    "\n",
    "## 0. Evaluación\n",
    "\n",
    "El proyecto se realiza de forma individual. Se entrega a más tardar el **lunes 30 de noviembre** en su repositorio GitHub.\n",
    "\n",
    "**Pauta de evaluación:**\n",
    "\n",
    "Competencia 1: Aplicar un protocolo de aprendizaje supervisado para resolver un problema clasificación estandar, utilizando un entorno de programación en Python\n",
    "\n",
    "- < 2 : El protocolo de aprendizaje supervisado utilizado es incompleto y/o presenta errores importantes\n",
    "- 2 a 3.9 : El protocolo de aprendizaje supervisado utilizado es incompleto o presenta un error importante\n",
    "- 4 a 5.5 : El protocolo de aprendizaje es completo, no tiene error, pero las estrategias utilizadas son relativamente simples y el rendimiento de los modelos es perfectible.\n",
    "- 5.6 a 7.0 : El protocolo de aprendizaje es completo, no tiene error y al menos una de las estrategias utilizadas a necesitado un trabajado más avanzado y/o permite obtener un mejor rendimiento.\n",
    "\n",
    "Competencia 2: Explicar el rendimiento de un modelo de clasificación aplicando un protocolo de evaluación Precision/Recall/F-Score\n",
    "\n",
    "- < 2 : El trabajo no presenta explicaciones del rendimiento de los modelos de clasificación\n",
    "- 2 a 3.9 : El trabajo presenta algunas explicaciones pero tienen errores.\n",
    "- 4 a 5.5 : El trabajo presenta explicaciones correctas del rendimiento de los modelos\n",
    "- 5.6 a 7 : El trabajo presenta explicaciones correctas del rendimiento de los modelos y además presenta un método para explicar las decisiones/errores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "**Nombre: Victor Moya Velásquez** \n",
    "\n",
    "A continuación se realizará un análisis del dataset para entontrar la mejor forma de clasificar la clase del objeto según un algoritmo predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/pdta-del-colegio...</td>\n",
       "      <td>Pdta. del Colegio de Matronas explicó los ries...</td>\n",
       "      <td>La Federación de Estudiantes de la Universidad...</td>\n",
       "      <td>2018-03-29 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/defensoria-ninez...</td>\n",
       "      <td>Defensoría de la Niñez pide al Estado velar po...</td>\n",
       "      <td>La Defensoría de la Niñez emitió este domingo ...</td>\n",
       "      <td>2020-08-02 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/cuanto-les-pagar...</td>\n",
       "      <td>¿Cuánto les pagarán a los vocales de mesa?</td>\n",
       "      <td>El monto del bono es de dos tercios de Unidad ...</td>\n",
       "      <td>2016-10-20 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/sobrino-de-aleja...</td>\n",
       "      <td>Sobrino de Alejandro Navarro intenta “funar” e...</td>\n",
       "      <td>Una nueva polémica tiene esta carrera presiden...</td>\n",
       "      <td>2017-11-13 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/pais/analisis-sobre-e...</td>\n",
       "      <td>Análisis sobre el aumento de impuestos para al...</td>\n",
       "      <td>Especialistas recomiendan no consumir más de 2...</td>\n",
       "      <td>2014-05-05 00:00:00.000000</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/playstati...</td>\n",
       "      <td>PlayStation 5 vs Xbox Series X: Mira la compar...</td>\n",
       "      <td>Las compañías ya han revelado muchos detalles ...</td>\n",
       "      <td>2020-09-18 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/android-l...</td>\n",
       "      <td>Android le dará “una paliza” a Windows en 2013</td>\n",
       "      <td>Se proyecta que tras un virtual empate en 2012...</td>\n",
       "      <td>2013-04-04 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/regalos-t...</td>\n",
       "      <td>Regalos tecnológicos marcaron pauta en Navidad</td>\n",
       "      <td>Tablets y smartphones fueron los regalos tecno...</td>\n",
       "      <td>2012-12-26 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/jugar-con...</td>\n",
       "      <td>Jugar con Fox en Starlink vale totalmente la p...</td>\n",
       "      <td>Crecí jugando clásicos de naves como Terminal ...</td>\n",
       "      <td>2018-10-30 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>chile</td>\n",
       "      <td>cnnchile</td>\n",
       "      <td>https://www.cnnchile.com/tecnologias/konami-la...</td>\n",
       "      <td>Konami lanza PES 2018 de forma gratuita para i...</td>\n",
       "      <td>Konami Digital Entertainment ha anunciado que ...</td>\n",
       "      <td>2017-11-10 00:00:00.000000</td>\n",
       "      <td>tecnologias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country media_outlet                                                url  \\\n",
       "0      chile     cnnchile  https://www.cnnchile.com/pais/pdta-del-colegio...   \n",
       "1      chile     cnnchile  https://www.cnnchile.com/pais/defensoria-ninez...   \n",
       "2      chile     cnnchile  https://www.cnnchile.com/pais/cuanto-les-pagar...   \n",
       "3      chile     cnnchile  https://www.cnnchile.com/pais/sobrino-de-aleja...   \n",
       "4      chile     cnnchile  https://www.cnnchile.com/pais/analisis-sobre-e...   \n",
       "...      ...          ...                                                ...   \n",
       "6995   chile     cnnchile  https://www.cnnchile.com/tecnologias/playstati...   \n",
       "6996   chile     cnnchile  https://www.cnnchile.com/tecnologias/android-l...   \n",
       "6997   chile     cnnchile  https://www.cnnchile.com/tecnologias/regalos-t...   \n",
       "6998   chile     cnnchile  https://www.cnnchile.com/tecnologias/jugar-con...   \n",
       "6999   chile     cnnchile  https://www.cnnchile.com/tecnologias/konami-la...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Pdta. del Colegio de Matronas explicó los ries...   \n",
       "1     Defensoría de la Niñez pide al Estado velar po...   \n",
       "2            ¿Cuánto les pagarán a los vocales de mesa?   \n",
       "3     Sobrino de Alejandro Navarro intenta “funar” e...   \n",
       "4     Análisis sobre el aumento de impuestos para al...   \n",
       "...                                                 ...   \n",
       "6995  PlayStation 5 vs Xbox Series X: Mira la compar...   \n",
       "6996     Android le dará “una paliza” a Windows en 2013   \n",
       "6997     Regalos tecnológicos marcaron pauta en Navidad   \n",
       "6998  Jugar con Fox en Starlink vale totalmente la p...   \n",
       "6999  Konami lanza PES 2018 de forma gratuita para i...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     La Federación de Estudiantes de la Universidad...   \n",
       "1     La Defensoría de la Niñez emitió este domingo ...   \n",
       "2     El monto del bono es de dos tercios de Unidad ...   \n",
       "3     Una nueva polémica tiene esta carrera presiden...   \n",
       "4     Especialistas recomiendan no consumir más de 2...   \n",
       "...                                                 ...   \n",
       "6995  Las compañías ya han revelado muchos detalles ...   \n",
       "6996  Se proyecta que tras un virtual empate en 2012...   \n",
       "6997  Tablets y smartphones fueron los regalos tecno...   \n",
       "6998  Crecí jugando clásicos de naves como Terminal ...   \n",
       "6999  Konami Digital Entertainment ha anunciado que ...   \n",
       "\n",
       "                            date     category  \n",
       "0     2018-03-29 00:00:00.000000         pais  \n",
       "1     2020-08-02 00:00:00.000000         pais  \n",
       "2     2016-10-20 00:00:00.000000         pais  \n",
       "3     2017-11-13 00:00:00.000000         pais  \n",
       "4     2014-05-05 00:00:00.000000         pais  \n",
       "...                          ...          ...  \n",
       "6995  2020-09-18 00:00:00.000000  tecnologias  \n",
       "6996  2013-04-04 00:00:00.000000  tecnologias  \n",
       "6997  2012-12-26 00:00:00.000000  tecnologias  \n",
       "6998  2018-10-30 00:00:00.000000  tecnologias  \n",
       "6999  2017-11-10 00:00:00.000000  tecnologias  \n",
       "\n",
       "[7000 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "df = pd.read_csv('cnnchile_7000.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se limpiará el dataset para analizar que datos son innecesarios o que sean necesario cambiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tendencias</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tecnologias</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pais</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mundo</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economia</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deportes</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cultura</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  count(*)\n",
       "0   tendencias      1000\n",
       "1  tecnologias      1000\n",
       "2         pais      1000\n",
       "3        mundo      1000\n",
       "4     economia      1000\n",
       "5     deportes      1000\n",
       "6      cultura      1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "q=\"\"\"SELECT category, count(*) FROM df GROUP BY category ORDER BY count(*) DESC;\"\"\"\n",
    "result=sqldf(q)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chile</th>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>6999</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         media_outlet   url  title  text  date  category\n",
       "country                                                 \n",
       "chile            7000  7000   6999  7000  7000      7000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['country']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el campo **country** toma solo un posible valor, entonces podemos eliminarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['country'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminaremos los datos irrelevantes:  \n",
    "\n",
    "- media_outlet   \n",
    "- url\n",
    "- title()\n",
    "- date(por ser una fecha)\n",
    "\n",
    "Estos datos no tienen relevancia para detectar la clase del objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['media_outlet','date','url','title'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos los valores de la columna **category** por valores numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"].replace({'tendencias':0, 'tecnologias':1, 'pais':2, 'mundo':3, 'economia':4, 'deportes':5,'cultura':6 }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existen datos nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística es un tipo de análisis de regresión utilizado para predecir el resultado de una variable categórica en función de las variables independientes o predictoras. \n",
    "\n",
    "Realizaré el modelo de predicción utilizando regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import es_core_news_sm\n",
    "\n",
    "nlp = es_core_news_sm.load ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(text):\n",
    "    \n",
    "    mytokens = nlp(text)\n",
    "\n",
    "    #Guardamos las palabras como características si corresponden a ciertas categorias gramaticales\n",
    "    mytokens = [ word for word in mytokens if word.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"] ]\n",
    "    \n",
    "    #Transformamos las palabras en minusculas\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "6995    1\n",
       "6996    1\n",
       "6997    1\n",
       "6998    1\n",
       "6999    1\n",
       "Name: category, Length: 7000, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text'] \n",
    "ylabels = df['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.7)\n",
    "ylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = feature_extraction, min_df=0., max_df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizing',\n",
       "                 TfidfVectorizer(min_df=0.0,\n",
       "                                 tokenizer=<function feature_extraction at 0x000002603D46E4C0>)),\n",
       "                ('learning', LogisticRegression())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_2 = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([('vectorizing', tfidf_vector),\n",
    "                 ('learning', model_2)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 6 ... 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = pipe.predict(X_test)\n",
    "predicted_proba = pipe.predict_proba(X_test)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7514285714285714\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64       677\n",
      "           1       0.78      0.61      0.68       697\n",
      "           2       0.79      0.64      0.71       723\n",
      "           3       0.72      0.76      0.74       689\n",
      "           4       0.69      0.85      0.76       695\n",
      "           5       0.92      0.82      0.87       722\n",
      "           6       0.82      0.90      0.86       697\n",
      "\n",
      "    accuracy                           0.75      4900\n",
      "   macro avg       0.76      0.75      0.75      4900\n",
      "weighted avg       0.76      0.75      0.75      4900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, predicted)\n",
    "#print(confusion_matrix)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión y recall de la categoria **tendecia** es baja con respecto a las otras categorias dando como resultado que el modelo no logra clasificar la categoria correctamente. En el caso del recall, es bajo en las categorias **tecnologias**, **pais**, pero con un presicion alta concluyendo que el modelo no detecta la categoria muy bien, pero cuando lo hace es altamente confiable. Con respecto a las otras categorias se comporta muy bien el modelo. En el caso de la categoria **economia** el modelo detecta bien la categoria pero también incluye muestras de otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teorema de Bayes:\n",
    "\n",
    "<img src=\"naivebayes.jpeg\" />\n",
    "\n",
    "**Modelo probabilístico que asume que existe una independencia entre las caractéristicas.**\n",
    "\n",
    "\n",
    "¿Qué se aprende?: probabilidades\n",
    "\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Cuando la suposición independiente se mantiene, entonces este clasificador da una precisión excepcional.\n",
    "- Es fácil de implementar ya que sólo se debe calcular la probabilidad\n",
    "- Funciona bien con dimensiones altas como la clasificación de texto.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Si la suposición independiente no se mantiene, entonces el rendimiento es muy bajo.\n",
    "\n",
    "- Suavizar resulta ser un paso obligado cuando la probabilidad de una característica resulta ser cero en una clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "model_nb = Pipeline([('vectorizing', tfidf_vector),\n",
    "                 ('learning', nb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizing',\n",
       "                 TfidfVectorizer(min_df=0.0,\n",
       "                                 tokenizer=<function feature_extraction at 0x0000017B6603CC10>)),\n",
       "                ('learning', MultinomialNB())])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132  48  14   9   8  16  64]\n",
      " [ 18 231   4   2  22   2  17]\n",
      " [  1   9 219  22  33   1   7]\n",
      " [  5  16  23 225  17   2  11]\n",
      " [  1  20  23   3 265   0   1]\n",
      " [  8   9   6   7   8 253   8]\n",
      " [  1   2   4   9   3   0 291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.45      0.58       291\n",
      "           1       0.69      0.78      0.73       296\n",
      "           2       0.75      0.75      0.75       292\n",
      "           3       0.81      0.75      0.78       299\n",
      "           4       0.74      0.85      0.79       313\n",
      "           5       0.92      0.85      0.88       299\n",
      "           6       0.73      0.94      0.82       310\n",
      "\n",
      "    accuracy                           0.77      2100\n",
      "   macro avg       0.78      0.77      0.76      2100\n",
      "weighted avg       0.78      0.77      0.76      2100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predicted)\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión de la categoria **tendecia** con respecto al modelo anterior se comporta de mejor manera, pero cayendo su recall, el modelo no detecta la categoria muy bien, pero cuando lo hace es altamente confiable. En otras categorias, en el caso de **tecnologia** la presicion baja con respecto al recall, siendo esto que el modelo detecta bien la categoria pero también incluye muestras de otras categorias. Pero en general el recall y la precision se comporta de mejor manera con respecto al modelo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=50, max_depth=None, min_samples_split=10, random_state=0)\n",
    "\n",
    "model_random_forest = Pipeline([('vectorizing', tfidf_vector),\n",
    "                 ('learning', random_forest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo para entrenar:95.24853610992432\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model_random_forest.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"tiempo para entrenar:\" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo para predecir:208.99423122406006\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "predicted = model_random_forest.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(\"tiempo para predecir:\" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[423  61  10  29  30  35  89]\n",
      " [158 363  21  16  67  28  44]\n",
      " [ 78  20 373  95 126  11  20]\n",
      " [ 66  12  58 414  82  18  39]\n",
      " [ 46  22  55  14 554   1   3]\n",
      " [ 73   4   8  15  35 578   9]\n",
      " [ 35  11   6  14   2   7 622]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.62      0.54       677\n",
      "           1       0.74      0.52      0.61       697\n",
      "           2       0.70      0.52      0.59       723\n",
      "           3       0.69      0.60      0.64       689\n",
      "           4       0.62      0.80      0.70       695\n",
      "           5       0.85      0.80      0.83       722\n",
      "           6       0.75      0.89      0.82       697\n",
      "\n",
      "    accuracy                           0.68      4900\n",
      "   macro avg       0.69      0.68      0.68      4900\n",
      "weighted avg       0.69      0.68      0.68      4900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predicted)\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión y el recall de la categoria **tendecia** con respecto al modelo no logra clasificar la categoria correctamente. En otras categorias, en el caso de **tecnologia**, **pais** y **mundo** la presicion es buena, el modelo no detecta las categorias muy bien, pero cuando lo hace es altamente confiable. En la categoria **economia** el recall es alto y la presicion baja dando como resultado que el modelo detecta bien la categoria pero también incluye muestras de otras categorias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy frecuente encontrarnos con datasets con clases desbalanceadas, de hecho… lo más raro sería encontrar datasets bien equilibrados, en nuestro caso la datasets esta balanceada lo que ayudo mucho a la hora de analizar. De los modelos propuestos en este trabajo, podemos concluir que el modelo con mejor \"rendimiento\" a la hora de analizar los resultados es el de Naïve Bayes, en el cual nos da un mejor resultado con respecto a los otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
